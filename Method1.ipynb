{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys,getopt\n",
    "import requests\n",
    "import csv\n",
    "import Orange\n",
    "from Orange.data import Table,Domain, DiscreteVariable, ContinuousVariable\n",
    "from orangecontrib.associate.fpgrowth import * \n",
    "\n",
    "#stats\n",
    "from scipy import sparse\n",
    "import scipy.stats as ss\n",
    "\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib_venn as venn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv and convert it to DataFrame\n",
    "items=set()\n",
    "\n",
    "with open('groceries.csv') as data:\n",
    "    read_data = csv.reader(data,delimiter=\",\")\n",
    "    for i,line in enumerate(read_data):\n",
    "        items.update(line)\n",
    "        \n",
    "output_list = list()\n",
    "\n",
    "with open('groceries.csv') as data:\n",
    "    read_data = csv.reader(data,delimiter=\",\")\n",
    "    for i,line in enumerate(read_data):\n",
    "        row_value = {item:0 for item in items}\n",
    "        row_value.update({item:1 for item in line})   #if item is present in that transcation, set row_value to 1 for that item\n",
    "        output_list.append(row_value)\n",
    "        \n",
    "grocery_df = pd.DataFrame(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the DataFrame\n",
    "grocery_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical Description\n",
    "grocery_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 20 \"sold items\" that occur in the dataset\n",
    "total_count_of_items = sum(grocery_df.sum())\n",
    "print(\"Total count of items: \", total_count_of_items)\n",
    "\n",
    "item_sort_df = grocery_df.sum().sort_values(ascending = False).reset_index()\n",
    "item_sort_df.rename(columns={item_sort_df.columns[0]:'item_name',item_sort_df.columns[1]:'item_count'}, inplace=True)\n",
    "item_sort_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of top 20 \"sold items\" that occur in the dataset\n",
    "objects = (list(item_sort_df['item_name'].head(20)))\n",
    "y = np.arange(len(objects))\n",
    "count = list(item_sort_df['item_count'].head(20))\n",
    " \n",
    "plt.bar(y, count, align='center', alpha=0.8)\n",
    "plt.xticks(y, objects, rotation='vertical')\n",
    "plt.ylabel('Item count')\n",
    "plt.title('Sales distribution of top 20 sold items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contribution of top 20 \"sold items\" to total sales\n",
    "item_sort_df['item_perc'] = item_sort_df['item_count']/total_count_of_items #each item's contribution \n",
    "item_sort_df['total_perc'] = item_sort_df.item_perc.cumsum() #cumulative contribution of top items\n",
    "\n",
    "print(item_sort_df[item_sort_df.total_perc <= 0.5].shape)\n",
    "\n",
    "item_sort_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Orange Table\n",
    "input_assoc_rules = grocery_df\n",
    "domain_grocery = Domain([DiscreteVariable.make(name='item',values=['0', '1']) for item in input_assoc_rules.columns])\n",
    "data_gro_1 = Orange.data.Table.from_numpy(domain=domain_grocery,  X=input_assoc_rules.as_matrix(),Y= None)\n",
    "data_gro_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prune Dataset for frequently purchased items\n",
    "def prune_dataset(input_df, length_trans, total_sales_perc, start_item = None, end_item = None):\n",
    "    if 'total_items' in input_df.columns:\n",
    "        del(input_df['total_items'])\n",
    "    item_count = input_df.sum().sort_values(ascending = False).reset_index()  \n",
    "    total_items = sum(input_df.sum().sort_values(ascending = False))\n",
    "    item_count.rename(columns={item_count.columns[0]:'item_name',item_count.columns[1]:'item_count'}, inplace=True)\n",
    "    \n",
    "    if not start_item and not end_item: \n",
    "        item_count['item_perc'] = item_count['item_count']/total_items  #each percent\n",
    "        item_count['total_perc'] = item_count.item_perc.cumsum()     #cumulative\n",
    "        selected_items= list(item_count[item_count.total_perc < total_sales_perc].item_name.sort_values())\n",
    "        input_df['total_items'] = input_df[selected_items].sum(axis = 1)\n",
    "        input_df = input_df[input_df.total_items >= length_trans]   #transactions with at least length_trans items\n",
    "        del(input_df['total_items'])\n",
    "        return input_df[selected_items], item_count[item_count.total_perc < total_sales_perc] #comparing cumulative perc\n",
    "    \n",
    "    elif end_item > start_item:\n",
    "        selected_items = list(item_count[start_item:end_item].item_name)\n",
    "        input_df['total_items'] = input_df[selected_items].sum(axis = 1)\n",
    "        input_df = input_df[input_df.total_items >= length_trans]\n",
    "        del(input_df['total_items'])\n",
    "        return input_df[selected_items],item_count[start_item:end_item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df, item_counts = prune_dataset(input_df=grocery_df, length_trans=2,total_sales_perc=0.4)\n",
    "print(\"Shape: \",output_df.shape)\n",
    "print(\"Selected items: \", list(output_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Association Rule Mining with FP Growth\n",
    "input_assoc_rules = output_df  \n",
    "domain_grocery = Domain([DiscreteVariable.make(name=item,values=['0', '1']) for item in input_assoc_rules.columns])\n",
    "data_gro_1 = Orange.data.Table.from_numpy(domain=domain_grocery,  X=input_assoc_rules.as_matrix(),Y= None)\n",
    "data_gro_1_en, mapping = OneHot.encode(data_gro_1, include_class=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support=0.01\n",
    "num_trans = input_assoc_rules.shape[0]*min_support\n",
    "print(\"Number of required transactions = \", int(num_trans))\n",
    "itemsets = dict(frequent_itemsets(data_gro_1_en, min_support=min_support))   #dict-- key:value pair\n",
    "print(len(itemsets), \" itemsets have a support of \", min_support*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.3\n",
    "rules_df = pd.DataFrame()\n",
    "\n",
    "if len(itemsets) < 1000000: \n",
    "    rules = [(P, Q, supp, conf)\n",
    "    for P, Q, supp, conf in association_rules(itemsets, confidence)\n",
    "       if len(Q) == 1 ]\n",
    "    print(len(rules))\n",
    "\n",
    "    names = {item: '{}={}'.format(var.name, val)\n",
    "        for item, var, val in OneHot.decode(mapping, data_gro_1, mapping)}\n",
    "    \n",
    "    eligible_antecedent = [v for k,v in names.items() if v.endswith(\"1\")]\n",
    "    \n",
    "    N = input_assoc_rules.shape[0]\n",
    "    \n",
    "    rule_stats = list(rules_stats(rules, itemsets, N))\n",
    "    \n",
    "    rule_list_df = []\n",
    "    for ex_rule_from_rule_stat in rule_stats:\n",
    "        ante = ex_rule_from_rule_stat[0]            \n",
    "        cons = ex_rule_from_rule_stat[1]\n",
    "        named_cons = names[next(iter(cons))]\n",
    "        if named_cons in eligible_antecedent:\n",
    "            rule_lhs = [names[i][:-2] for i in ante if names[i] in eligible_antecedent]\n",
    "            ante_rule = ', '.join(rule_lhs)\n",
    "            if ante_rule and len(rule_lhs)>1 :\n",
    "                rule_dict = {'support' : ex_rule_from_rule_stat[2],\n",
    "                             'confidence' : ex_rule_from_rule_stat[3],\n",
    "                             'coverage' : ex_rule_from_rule_stat[4],\n",
    "                             'strength' : ex_rule_from_rule_stat[5],\n",
    "                             'lift' : ex_rule_from_rule_stat[6],\n",
    "                             'leverage' : ex_rule_from_rule_stat[7],\n",
    "                             'antecedent': ante_rule,\n",
    "                             'consequent':named_cons[:-2] }\n",
    "                rule_list_df.append(rule_dict)\n",
    "    rules_df = pd.DataFrame(rule_list_df)\n",
    "    print(\"Raw rules data frame of {} rules generated\".format(rules_df.shape[0]))\n",
    "    if not rules_df.empty:\n",
    "        pruned_rules_df = rules_df.groupby(['antecedent','consequent']).max().reset_index()\n",
    "    else:\n",
    "        print(\"Unable to generate any rule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting rules in grocery data set\n",
    "(pruned_rules_df[['antecedent','consequent',\n",
    "                  'support','confidence','lift']].groupby('consequent')\n",
    "                                                 .max()\n",
    "                                                 .reset_index()\n",
    "                                                 .sort_values(['lift', 'support','confidence'],\n",
    "                                                              ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
